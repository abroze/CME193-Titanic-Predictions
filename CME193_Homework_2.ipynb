{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LB2zQvr_qObR"
   },
   "source": [
    "# CME193 - Homework 2\n",
    "\n",
    "In this assignment, you'll be analyzing an interesting dataset: the passengers of the ship *Titanic*. As you are probably familiar, the *Titanic* was a ship that collided with an iceberg on April 15, 1912 and sank. About one-third of the passengers survived. We are interested in analyzing what factors are correlated with whether a person survived (whether the person was traveling with family, the person's sex, the person's age, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OEO_grt3qObS"
   },
   "source": [
    "## Question 1: Loading the dataset    \n",
    "\n",
    "The dataset contains the following columns:\n",
    "- `Survived`: `1` if the person survived, `0` if not\n",
    "- `Pclass`: the ticket class the person was travelling under, `1` for 1st class, `2` for 2nd class, `3` for 3rd class\n",
    "- `Name`: name\n",
    "- `Sex`: sex, `male` for male, `female` for female\n",
    "- `Age`: age\n",
    "- `Siblings/Spouses Aboard`: the number of siblings and spouses aboard\n",
    "- `Parents/Children Aboard`: the number of parents and children aboard\n",
    "- `Fare`: the amount paid for the ticket, in pounds\n",
    "\n",
    "Eventually, we would like to use a classification algorithm to predict the `Survived` column from the other columns (besides `Name`). This means we need to convert the non-numeric columns into numeric columns (or boolean columns, for which `True` and `False` can be interpreted as `1` and `0` respectively).\n",
    "\n",
    "You can find the dataset at the following URL (from CS 109, originally from Kaggle):\n",
    "\n",
    "    http://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv\n",
    "\n",
    "Load this CSV file into a Pandas dataframe and look at the data. Convert `Pclass` and `Sex` into boolean columns; that is, create four new boolean columns, `Female`, `1st Class`, `2nd Class`, and `3rd Class`, with the appropriate values. For example, `Female` would be `True` if the person is female, `False` if the person is male.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "sa_CNYMmqObT"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Female</th>\n",
       "      <th>1st Class</th>\n",
       "      <th>2nd Class</th>\n",
       "      <th>3rd Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. Owen Harris Braund</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. John Bradley (Florence Briggs Thayer) Cum...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Miss. Laina Heikkinen</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. Jacques Heath (Lily May Peel) Futrelle</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. William Henry Allen</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass                                               Name  \\\n",
       "0         0       3                             Mr. Owen Harris Braund   \n",
       "1         1       1  Mrs. John Bradley (Florence Briggs Thayer) Cum...   \n",
       "2         1       3                              Miss. Laina Heikkinen   \n",
       "3         1       1        Mrs. Jacques Heath (Lily May Peel) Futrelle   \n",
       "4         0       3                            Mr. William Henry Allen   \n",
       "\n",
       "      Sex   Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  \\\n",
       "0    male  22.0                        1                        0   7.2500   \n",
       "1  female  38.0                        1                        0  71.2833   \n",
       "2  female  26.0                        0                        0   7.9250   \n",
       "3  female  35.0                        1                        0  53.1000   \n",
       "4    male  35.0                        0                        0   8.0500   \n",
       "\n",
       "   Female  1st Class  2nd Class  3rd Class  \n",
       "0   False      False      False       True  \n",
       "1    True       True      False      False  \n",
       "2    True      False      False       True  \n",
       "3    True       True      False      False  \n",
       "4   False      False      False       True  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('http://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv')\n",
    "\n",
    "# TODO: YOUR CODE HERE\n",
    "df['Female'] = df['Sex'] == 'female'\n",
    "df['1st Class'] = df['Pclass'] == 1\n",
    "df['2nd Class'] = df['Pclass'] == 2\n",
    "df['3rd Class'] = df['Pclass'] == 3\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7RFCaqlBqObV"
   },
   "source": [
    "## Question 2: Building the dataset\n",
    "Next, let's convert our dataset into NumPy arrays. Create a NumPy array `X` derived from the Pandas dataframe with the numerical and boolean columns, that is: `['Age', 'Siblings/Spouses Aboard', 'Parents/Children Aboard', 'Fare', 'Female', '1st Class', '2nd Class', '3rd Class']`. Create a NumPy vector `y` derived from the `Survived` column. Ensure that the entries of both `X` and `y` are floating point numbers. (Hint: if `a` is a NumPy array, then `a.astype(float)` converts the entries to floats.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "i42sFd6bqObV"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Siblings/Spouses Aboard</th>\n",
       "      <th>Parents/Children Aboard</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Female</th>\n",
       "      <th>1st Class</th>\n",
       "      <th>2nd Class</th>\n",
       "      <th>3rd Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age  Siblings/Spouses Aboard  Parents/Children Aboard     Fare  Female  \\\n",
       "0  22.0                      1.0                      0.0   7.2500     0.0   \n",
       "1  38.0                      1.0                      0.0  71.2833     1.0   \n",
       "2  26.0                      0.0                      0.0   7.9250     1.0   \n",
       "3  35.0                      1.0                      0.0  53.1000     1.0   \n",
       "4  35.0                      0.0                      0.0   8.0500     0.0   \n",
       "\n",
       "   1st Class  2nd Class  3rd Class  \n",
       "0        0.0        0.0        1.0  \n",
       "1        1.0        0.0        0.0  \n",
       "2        0.0        0.0        1.0  \n",
       "3        1.0        0.0        0.0  \n",
       "4        0.0        0.0        1.0  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: YOUR CODE HERE\n",
    "X = df[['Age', 'Siblings/Spouses Aboard', 'Parents/Children Aboard', 'Fare', 'Female', '1st Class', '2nd Class', '3rd Class']].astype(float)\n",
    "y = df['Survived'].astype(float)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJqAwNkJqObV"
   },
   "source": [
    "## Question 3: Logistic regression\n",
    "Logistic regression is a classification algorithm that comes with scikit-learn. In this case, we would like to predict one of two classes, `1` if the person survived, `0` if the person did not. Normally, we would split our dataset into a training set and a test set, but for simplicity we will not do that here; instead we will train on our entire dataset.\n",
    "\n",
    "Using scikit-learn, fit a logistic regression model to the dataset we created in Question 2. What percentage of the passengers' outcomes does the model correctly predict? What does the model think about the fate of a 30-year-old male travelling alone who paid 50 pounds for his 2nd-class ticket?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "pGXuz7vhqObV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model predicts 80.38 % of the passengers' outcomes correctly\n",
      "The 30-year old man has not survived according to the model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/albanbroze/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn import linear_model\n",
    "import numpy as np\n",
    "\n",
    "model = linear_model.LogisticRegression()\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "perc_corr_pred = model.score(X, y) * 100\n",
    "\n",
    "man_model = np.array([30, 0, 0, 50, False, False, True, False]).reshape(1,-1)\n",
    "man_model.astype(float)\n",
    "\n",
    "if model.predict(man_model) == 0:\n",
    "    txt = \"not survived\"\n",
    "elif model.predict(man_model) == 1:\n",
    "    txt = \"survived\"\n",
    "\n",
    "print(\"The model predicts {} % of the passengers' outcomes correctly\".format(round(perc_corr_pred, 2)))\n",
    "print(\"The 30-year old man has \" + txt + \" according to the model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e7jg1W_BqObX"
   },
   "source": [
    "## Question 4: Defining the model\n",
    "As an exercise, we will now do logistic regression again, but this time \"manually\" -- without the use of scikit-learn -- by solving the underlying optimization problem. To do so, we'll make use of SciPy's `special` and `optimize` packages.\n",
    "\n",
    "Consider a single observation $x$ (a single passenger), represented by a vector of length $k$. Logistic regression defines a model with two parameters, $\\alpha$ and $\\beta$, where $\\alpha$ is a number and $\\beta$ is a vector of length $k$. Assuming we know $\\alpha$ and $\\beta$, the probability that $x$ survives is the number\n",
    "$$ \\text{probability that }x\\text{ survives} = \\frac{1}{1 + \\exp(-(\\alpha + x^T \\beta)) }.$$\n",
    "Our eventual goal is to find the values for $\\alpha$ and $\\beta$ that results in a probability that best matches the observed outcome for $x$.\n",
    "\n",
    "Define a function `probability_of_surviving(alpha, beta, X)` that computes probabilities of the passengers in `X` surviving,\n",
    "$$ \\frac{1}{1 + \\exp(-(\\alpha + X \\beta )) },$$\n",
    "where:\n",
    "- `alpha` is a number $\\alpha$\n",
    "- `beta` is a vector $\\beta$ of length $k$\n",
    "- `X` is an $n$-by-$k$ matrix $X$, where each of the $n$ rows corresponds to an observation (a passenger), and each column corresponds to a feature.\n",
    "\n",
    "This function should output a vector of length $n$, with each entry being the probability that each person survives, assuming we know $\\alpha$ and $\\beta$. Note that $X\\beta$ should be interpreted as matrix multiplication, but all other operations (addition, exponential, division) operate elementwise. (Hint: check out SciPy's `special.expit`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "QC6DpUycqObX"
   },
   "outputs": [],
   "source": [
    "# TODO: implemenet the function below\n",
    "\n",
    "from scipy import special, optimize\n",
    "\n",
    "def probability_of_surviving(alpha, beta, X):\n",
    "    return special.expit(alpha + X@beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_c_kJXCqObX"
   },
   "source": [
    "## Question 5: Defining the loss\n",
    "Our goal is to find the $\\alpha$ and $\\beta$ values that best match the observed data $(X, y)$. To do this, we will construct a loss function that, when given $\\alpha$ and $\\beta$, characterizes how good our predictions $\\hat{y}$ are compared to the ground truth $y$. \n",
    "\n",
    "Mathematically, our loss function will be $$\n",
    "    L(\\alpha, \\beta, X, y) = \\text{sum}(\\text{KL}(y, \\hat{y})) + \\frac{1}{2}\\beta^T \\beta,\n",
    "$$ where:\n",
    "- $\\hat{y}$ is the vector of predicted probabilities (from Question 4), which is computed from $\\alpha$, $\\beta$, and $X$\n",
    "- $\\text{KL}(y, \\hat{y})$ is the *Kullback-Liebler divergence*, which measures how different the ground truth $y$ is from the predicted probabilities $\\hat{y}$\n",
    "- $\\text{sum}(\\cdot)$ sums up the entries of a vector, in this case adding up the loss for each passenger in $X$\n",
    "- $\\frac{1}{2}\\beta^T \\beta$ is a *regularization term* that prevents overfitting.\n",
    "\n",
    "Define a function `logistic_regression_loss(alpha_beta, X, y)` that computes $L(\\alpha, \\beta, X, y)$, where\n",
    "- `alpha_beta` is a vector of length $1+ k$ that contains $\\alpha$ in its first entry and $\\beta$ in the remaining entries\n",
    "- `X` is an $n$-by-$k$ matrix $X$, where each of the $n$ rows corresponds to an observation (a passenger), and each column corresponds to a feature\n",
    "- `y` is a vector $y$ of length $n$, that is 1 if the passenger survived and 0 if they did not.\n",
    "\n",
    "(Hint: check out SciPy's `special.kl_div`.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "id": "b7EBj8QiqObX"
   },
   "outputs": [],
   "source": [
    "# TODO: Implement functions below\n",
    "def logistic_regression_loss(alpha_beta, X, y):\n",
    "    \n",
    "    alpha = alpha_beta[0]\n",
    "    beta = alpha_beta[1:]\n",
    "    \n",
    "    y_pred = probability_of_surviving(alpha, beta, X)\n",
    "    \n",
    "    loss = np.sum(special.kl_div(y, y_pred)) + 1/2 * np.linalg.norm(beta)**2\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rae3Y9bVqObY"
   },
   "source": [
    "## Question 6: Logistic regression (the hard way)\n",
    "Use SciPy's `optimize.minimize` to find the $\\alpha$ and $\\beta$ that best explain the data $(X,y)$. In other words, find $\\alpha$ and $\\beta$ that minimizes the function `logistic_regression_loss`. Use an initial guess of $\\alpha = 0$, $\\beta = 0$. Compare your result to the $\\alpha$ and $\\beta$ computed by scikit-learn, given by `model.intercept_` and `model.coef_`. (It will not match exactly but should be somewhat close.)\n",
    "\n",
    "(Hint: you'll need to make use of the `args` argument for `optimize.minimize` to pass in `X` and `y`. Also, you may get a warning that the desired error was not achieved, but you can ignore this.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "id": "-dBkaggoqObY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 alpha:  0.10352360064850934\n",
      "model 2 alpha:  0.12634090109401394\n",
      "\n",
      "model 1 beta:  [-0.04161514 -0.38656389 -0.09896949  0.00327638  2.63675698  1.12922887\n",
      "  0.06289571 -1.08233042]\n",
      "model 2 beta:  [-0.04302206 -0.36806956 -0.06156255  0.00386969  2.32004739  1.03282188\n",
      " -0.1387026  -0.89412047]\n"
     ]
    }
   ],
   "source": [
    "# TODO: use optimize.minimize to implement the logistic regression\n",
    "# AND compare the result to Q3 using scikit-learn\n",
    "\n",
    "x0 = np.zeros(len(X.columns)+1)\n",
    "res = optimize.minimize(logistic_regression_loss, x0=x0, args=(X,y))\n",
    "\n",
    "print(\"model 1 alpha: \", model.intercept_[0])\n",
    "print(\"model 2 alpha: \", res.x[0])\n",
    "print()\n",
    "print(\"model 1 beta: \", model.coef_[0])\n",
    "print(\"model 2 beta: \", res.x[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OrOZuHPIqObY"
   },
   "source": [
    "## Question 7: Predictions\n",
    "\n",
    "With what probability does the model learned in Question 6 think a 30-year-old male travelling alone who paid 50 pounds for his 2nd-class ticket will survive? What percentage of the passengers' outcomes does the model correctly predict, if we say that the model predicts survival if the probability of survival is greater than 0.5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "id": "W_HALpGKqObZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model thinks the man will survive with probability 24.8 %\n",
      "The model predicts 80.61 % of the passengers' outcomes correctly\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement your code here\n",
    "alpha = res.x[0]\n",
    "beta = res.x[1:]\n",
    "X_man = np.array([30, 0, 0, 50, False, False, True, False]).astype(float)\n",
    "\n",
    "print(\"The model thinks the man will survive with probability {} %\".format(round(probability_of_surviving(alpha, beta, X_man)*100,2)))\n",
    "\n",
    "pred = probability_of_surviving(alpha, beta, X)\n",
    "pred[pred > 0.5] = True\n",
    "pred[pred <= 0.5] = False\n",
    "pred_eval = (y == pred.astype(float))\n",
    "pred_eval_perc = np.count_nonzero(pred_eval)/len(pred_eval) * 100\n",
    "\n",
    "print(\"The model predicts {} % of the passengers' outcomes correctly\".format(round(pred_eval_perc, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AuWid3INqObZ"
   },
   "source": [
    "# Submission instructions\n",
    "\n",
    "Get a sharable link that can be viewed by anyone with the link, and submit it on gradescope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
